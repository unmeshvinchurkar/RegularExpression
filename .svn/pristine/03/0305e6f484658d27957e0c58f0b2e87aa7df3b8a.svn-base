package com.tokenizer;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import javax.imageio.stream.FileImageOutputStream;

import com.regular.expression.RegularExpParser;

public class Tokenizer {
	
	private boolean initialized = false;
	private String FILE_NAME = "code.txt";
	private TypeDefLoader loader;
	private StringBuffer tokenSb = new StringBuffer();
	private List<RegularExpParser> parserSet = new ArrayList<RegularExpParser>();
	private List<RegularExpParser> validparsers = new ArrayList<RegularExpParser>();	

	public Tokenizer() {
		loader = new TypeDefLoader();
	}

	public void reset() {
		initialized = false;
		parserSet.clear();
		validparsers.clear();
		tokenSb.setLength(0);
	}	

	private void _initializeParsers() {
		initialized = false;
		loader.load();
		Map<String, String> map = loader.getClassNameRegExMap();
		for (Entry<String, String> entry : map.entrySet()) {
			RegularExpParser parser = new RegularExpParser();
			parser.setClassName(entry.getKey());
			parser.compile(entry.getValue());
			parserSet.add(parser);
		}
		initialized = true;
	}

	private boolean _isBreakPoint(char c) {
		return c == '\n' || c == ' ' || c == '\t';
	}
	
	public List<Token> getTokens() {
		
		if (!initialized) {
			_initializeParsers();
		}
		File codeFile= new File(".//"+FILE_NAME);
		FileInputStream fin = null;
		
		try {
			fin= new FileInputStream(codeFile);
		} catch (FileNotFoundException e1) {
			e1.printStackTrace();
		}
		
		BufferedReader br = new BufferedReader(new InputStreamReader(fin));
		List<Token> tokens = new ArrayList<Token>();
		String line = null;
		validparsers.addAll(parserSet);

		try {
			Set<RegularExpParser> removeParsers = new LinkedHashSet<RegularExpParser>();
			int lineNo = 0;

			while ((line = br.readLine()) != null) {
				line = line.trim();
				
				// Added space as terminator
				line=line+" ";
				lineNo++;

				for (int i = 0; i < line.length(); i++) {
					char currentChar = line.charAt(i);

					boolean moved = false;

					if (!_isBreakPoint(currentChar)) {
						tokenSb.append(currentChar);

						for (RegularExpParser parser : validparsers) {
							
							if (parser.move(currentChar)) {
								moved = true;
							} else {
								if (!parser.isInFinalState()) {
									removeParsers.add(parser);
								}
							}
						}
						// If no parser is moved for currentChar, remove it from tokenSb
						if (!moved && tokenSb.length() > 0) {
							tokenSb.setLength(tokenSb.length() - 1);
						}
					}

					validparsers.removeAll(removeParsers);
					removeParsers.clear();

					if (tokenSb.length()>0  && ( !moved || _isBreakPoint(currentChar) )) {
						if (!validparsers.isEmpty()) {
							String token = tokenSb.toString();
							boolean foundToken = false;

							for (RegularExpParser parser : validparsers) {
								if (parser.isInFinalState()
										&& parser.getMoveCount() == token.length()) {
									tokens.add(new Token(parser.getClassName(),	token, lineNo, i - token.length()));
									//System.out.println(tokens);
									_reset();
									i--;
									foundToken = true;
									break;
								}
							}
							
							if(!foundToken){
								throw new RuntimeException("Invalid string at Line:" + lineNo+ " Column:"+ (i - tokenSb.length()));
							}
						} else {
							throw new RuntimeException("Invalid string at Line:" + lineNo+ " Column:"+ (i - tokenSb.length()));
						}
					}
				}
			}
		} catch (IOException e) {
		}

		return tokens;
	}
	
	private void _resetMachines() {
		for (RegularExpParser parser : parserSet) {
			parser.reset();
		}
	}

	private void _reset() {
		tokenSb.setLength(0);
		validparsers.clear();
		validparsers.addAll(parserSet);
		_resetMachines();
	}

	public static void main(String args[]) {
		Tokenizer tokenizer = new Tokenizer();
		System.out.println(tokenizer.getTokens());
	}
}
